<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">






  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-atom.min.css?v=1.0.2" rel="stylesheet">




  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



















  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.5.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.5.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.5.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.5.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Gradient Descennt 我们已经定义了代价函数J 而在这段视频中 我想向你们介绍梯度下降这种算法 这种算法可以将代价函数J最小化 梯度下降是很常用的算法 它不仅被用在线性回归上 它实际上被广泛的应用于机器学习领域中的众多领域 在后面课程中 为了解决其他线性回归问题 我们&amp;amp;&amp;amp;也将使用梯度下降法 最小化其他函数 而不仅仅是只用在本节课的代价函数J 因此在这个视频中 我将讲解">
<meta name="keywords" content="单变量线性回归,Linear-Regression">
<meta property="og:type" content="article">
<meta property="og:title" content="第二章 单变量线性回归(Linear Regression with One Variable)">
<meta property="og:url" content="http://www.fengwenhua.top/2018/11/15/第二章-单变量线性回归-Linear-Regression-with-One-Variable/index.html">
<meta property="og:site_name" content="江南小虫虫的博客">
<meta property="og:description" content="Gradient Descennt 我们已经定义了代价函数J 而在这段视频中 我想向你们介绍梯度下降这种算法 这种算法可以将代价函数J最小化 梯度下降是很常用的算法 它不仅被用在线性回归上 它实际上被广泛的应用于机器学习领域中的众多领域 在后面课程中 为了解决其他线性回归问题 我们&amp;amp;&amp;amp;也将使用梯度下降法 最小化其他函数 而不仅仅是只用在本节课的代价函数J 因此在这个视频中 我将讲解">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560718_677839576_1539945526">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560743_1565219096_1539945560">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560798_666068590_1539945598">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560828_2138414653_1539945611">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560836_1542066151_1539945624">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560853_1272028194_1539945641">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560865_949036406_1539945662">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560876_637224678_1539945680">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561001_1205108635_1539945758">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561065_1055239768_1539945798">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561083_1129145205_1539945818">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561100_393689345_1539945882">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561137_131391682_1539945928">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561170_2045903942_1539945980">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561190_832177929_1539945992">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561218_1102222000_1539946039">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561252_904671270_1539946074">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561410_371681908_1539946127">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561401_1069093686_1539946176">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561445_1568980368_1539946208">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561464_253805835_1539946231">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561479_1021372496_1539946255">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561493_322597671_1539946286">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561559_975182746_1539946335">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561584_1088750870_1539946381">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561607_175617464_1539946398">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561620_33298999_1539946410">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561636_1697292728_1539946422">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561656_442389494_1539946439">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561667_1647461546_1539946468">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561675_2093920258_1539946481">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561743_42538752_1539946555">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561818_666946699_1539946612">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561861_322362701_1539946651">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561892_649652808_1539951959">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561936_996217166_1539952078">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561956_1952955701_1539952499">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561971_576823992_1539952519">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562028_517004246_1539952542">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562040_769496498_1539952555">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562056_1050624241_1539952593">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562070_1456917132_1539952610">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562104_573736577_1539952665">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562122_1863333386_1539952686">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562131_948800849_1539952693">
<meta property="og:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562146_1798195049_1539952711">
<meta property="og:updated_time" content="2018-11-15T06:52:13.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第二章 单变量线性回归(Linear Regression with One Variable)">
<meta name="twitter:description" content="Gradient Descennt 我们已经定义了代价函数J 而在这段视频中 我想向你们介绍梯度下降这种算法 这种算法可以将代价函数J最小化 梯度下降是很常用的算法 它不仅被用在线性回归上 它实际上被广泛的应用于机器学习领域中的众多领域 在后面课程中 为了解决其他线性回归问题 我们&amp;amp;&amp;amp;也将使用梯度下降法 最小化其他函数 而不仅仅是只用在本节课的代价函数J 因此在这个视频中 我将讲解">
<meta name="twitter:image" content="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560718_677839576_1539945526">






  <link rel="canonical" href="http://www.fengwenhua.top/2018/11/15/第二章-单变量线性回归-Linear-Regression-with-One-Variable/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>第二章 单变量线性回归(Linear Regression with One Variable) | 江南小虫虫的博客</title>
  











  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">江南小虫虫的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.fengwenhua.top/2018/11/15/第二章-单变量线性回归-Linear-Regression-with-One-Variable/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="冯文华">
      <meta itemprop="description" content="记录日常学习与生活">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="江南小虫虫的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第二章 单变量线性回归(Linear Regression with One Variable)
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-11-14 20:22:59" itemprop="dateCreated datePublished" datetime="2018-11-14T20:22:59Z">2018-11-14</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-11-15 06:52:13" itemprop="dateModified" datetime="2018-11-15T06:52:13Z">2018-11-15</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/机器学习/机器学习入门/" itemprop="url" rel="index"><span itemprop="name">机器学习入门</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/11/15/第二章-单变量线性回归-Linear-Regression-with-One-Variable/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/2018/11/15/第二章-单变量线性回归-Linear-Regression-with-One-Variable/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/11/15/第二章-单变量线性回归-Linear-Regression-with-One-Variable/" class="leancloud_visitors" data-flag-title="第二章 单变量线性回归(Linear Regression with One Variable)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数：</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">8.7k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">14 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h2 id="Gradient-Descennt"><a href="#Gradient-Descennt" class="headerlink" title="Gradient Descennt"></a>Gradient Descennt</h2><blockquote>
<p>我们已经定义了<code>代价函数J</code> 而在这段视频中 我想向你们介绍<code>梯度下降</code>这种算法 <strong>这种算法可以将代价函数J最小化</strong> 梯度下降是很常用的算法 它不仅被用在线性回归上 它实际上被广泛的应用于机器学习领域中的众多领域 在后面课程中 为了解决其他线性回归问题 我们&amp;&amp;<strong>也将使用梯度下降法 最小化其他函数</strong> 而不仅仅是只用在本节课的代价函数J 因此在这个视频中 我将讲解用梯度下降算法最小化函数 J 在后面的视频中 我们还会将此算法应用于具体的 代价函数J中来解决线性回归问题 下面是问题概述</p>
</blockquote>
<ul>
<li>在这里 我们有一个函数$J(\theta_0, \theta_1)$ 也许这是一个线性回归的代价函数 也许是一些其他函数 要使其最小化 我们需要用一个算法 来最小化函数$J(\theta_0, \theta_1)$ 就像刚才说的 事实证明 梯度下降算法可应用于 多种多样的函数求解 所以想象一下如果你有一个函数 J(θ0, θ1, θ2, …,θn ) 你希望可以通过最小化 θ0到θn 来最小化此代价函数J(θ0 到θn) 用n个θ是为了证明梯度下降算法可以解决更一般的问题 但为了简洁起见 为了简化符号 在接下来的视频中 我只用两个参数</li>
<li><p>下面就是关于梯度下降的构想 我们要做的是 我们<strong>要开始对θ0和θ1 进行一些初步猜测</strong> 它们到底是什么其实并不重要 但<strong>通常的选择是将 θ0设为0 将θ1也设为0 将它们都初始化为0</strong> 我们在梯度下降算法中要做的 就是<strong>不停地一点点地改变 θ0和θ1 试图通过这种改变使得J(θ0, θ1)变小 直到我们找到 J 的最小值 或许是局部最小值</strong></p>
<a id="more"></a>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560718_677839576_1539945526" alt="_1526560718_677839576_1539945526_1526560718_677839576.png"></p>
</li>
<li><p>让我们通过一些图片来看看梯度下降法是如何工作的 我在试图让这个函数值最小 注意坐标轴 θ0和θ1在水平轴上 而函数 J在垂直坐标轴上 图形表面高度则是 J的值</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560743_1565219096_1539945560" alt="_1526560743_1565219096_1539945560_1526560743_1565219096.png"></p>
<ul>
<li>我们希望最小化这个函数 所以我们从 θ0和θ1的某个值出发 所以想象一下 <strong>对 θ0和θ1赋以某个初值 也就是对应于从这个函数表面上的某个起始点出发</strong> 对吧 所以<strong>不管 θ0和θ1的取值是多少 我将它们初始化为0 但有时你也可把它初始化为其他值</strong> 现在我希望大家把这个图像想象为一座山 想像类似这样的景色 公园中有两座山 想象一下你正站立在山的这一点上 站立在你想象的公园这座红色山上 在梯度下降算法中 我们<strong>要做的就是旋转360度 看看我们的周围 并问自己 我要在某个方向上 用小碎步尽快下山 这些小碎步需要朝什么方向?</strong></li>
<li>如果我们站在山坡上的这一点 你看一下周围 你会发现<strong>最佳的下山方向</strong> 大约是那个方向 好的 现在你在山上的新起点上</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560798_666068590_1539945598" alt="_1526560798_666068590_1539945598_1526560798_666068590.png"></p>
<ul>
<li>你再看看周围 然后再一次想想 我应该从什么方向迈着小碎步下山? 然后你按照自己的判断又迈出一步 往那个方向走了一步</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560828_2138414653_1539945611" alt="_1526560828_2138414653_1539945611_1526560828_2138414653.png"></p>
<ul>
<li><strong>然后重复上面的步骤</strong> 从这个新的点 你环顾四周 并<strong>决定从什么方向将会最快下山</strong> 然后又迈进了一小步 又是一小步 并依此类推 直到你接近这里 <strong>直到局部最低点的位置</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560836_1542066151_1539945624" alt="_1526560836_1542066151_1539945624_1526560836_1542066151.png"></p>
<ul>
<li>此外 这种下降有一个有趣的特点 第一次我们是从这个点开始进行梯度下降算法的 是吧 在这一点上从这里开始 现在想象一下 我们在刚才的右边一些的位置 对梯度下降进行初始化 想象我们在右边高一些的这个点 开始使用梯度下降 如果你重复上述步骤 停留在该点 并环顾四周 往下降最快的方向迈出一小步 然后环顾四周 又迈出一步 然后如此往复 如果你从右边不远处开始 梯度下降算法将会带你来到 这个右边的第二个局部最优处</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560853_1272028194_1539945641" alt="_1526560853_1272028194_1539945641_1526560853_1272028194.png"></p>
<ul>
<li>如果从刚才的第一个点出发 你会得到这个局部最优解 但如果你的起始点偏移了一些 起始点的位置略有不同 你<strong>会得到一个 非常不同的局部最优解 这就是梯度下降算法的一个特点</strong> 我们会在之后继续探讨这个问题</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560865_949036406_1539945662" alt="_1526560865_949036406_1539945662_1526560865_949036406.png"></p>
<ul>
<li>好的 这是我们从图中得到的直观感受 看看这个图 这是梯度下降算法的定义 我们<strong>将会反复做这些 直到收敛</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526560876_637224678_1539945680" alt="_1526560876_637224678_1539945680_1526560876_637224678.png"></p>
<ul>
<li>我们要<strong>更新参数 θj 方法是 用 θj 减去 α乘以这一部分</strong><ul>
<li><code>:= 表示赋值</code> 这是一个赋值运算符</li>
<li><code>等号 =</code> :写出<code>a=b</code> 那么这是一个判断为真的<strong>声明</strong> 如果我<strong>写 a=b 就是在断言 a的值是等于 b的值的</strong> 这是声明 声明 a的值 与b的值相同</li>
<li><code>α</code> :一个数字 被称为<code>学习速率</code><ul>
<li>什么是α呢? 在梯度下降算法中 它控制了 <strong>我们下山时会迈出多大的步子</strong> 因此如果 α值很大 那么相应的梯度下降过程中 我们会试图用大步子下山 如果α值很小 那么我们会迈着很小的小碎步下山 关于如何设置 α的值等内容 在之后的课程中 我会回到这里并且详细说明</li>
</ul>
</li>
<li>最后 是公式的这一部分<img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561001_1205108635_1539945758" alt="_1526561001_1205108635_1539945758_1526561001_1205108635.png">这是一个<strong>微分项</strong> 我现在不想谈论它 但我会推导出这个微分项 并告诉你到底这要如何计算 你们中有人大概比较熟悉微积分 但即使你不熟悉微积分 也不用担心 我会告诉你 对这一项 你最后需要做什么</li>
</ul>
</li>
<li>现在 在梯度下降算法中 还有一个更微妙的问题 在梯度下降中 我们要更新 θ0和θ1 当 j=0 和 j=1 时 会产生更新 所以你将更新 J θ0还有θ1 实现梯度下降算法的微妙之处是 在这个表达式中 如果你要更新这个等式 你<strong>需要同时更新 θ0和θ1</strong> 我的意思是在这个等式中 我们要这样更新 <code>θ0:=θ0 -</code> 一些东西 并更新 <code>θ1:=θ1 -</code> 一些东西 实现方法是 <strong>你应该计算公式右边的部分 通过那一部分计算出θ0和θ1的值 然后同时更新 θ0和θ1</strong> 让我进一步阐述这个过程</li>
<li>在梯度下降算法中 这是正确实现同时更新的方法 我要设 temp0等于这些 设temp1等于那些 所以首先计算出公式右边这一部分 然后将计算出的结果 一起存入 temp0和 temp1 之中 然后同时更新 θ0和θ1 因为这才是正确的实现方法</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561065_1055239768_1539945798" alt="_1526561065_1055239768_1539945798_1526561065_1055239768.png"></p>
<ul>
<li>与此相反 下面是不正确的实现方法 因为它没有做到同步更新 在这种不正确的实现方法中 我们计算 temp0 然后我们更新θ0 然后我们计算 temp1 然后我们将 temp1 赋给θ1 右边的方法和左边的区别是 让我们看这里 就是这一步 如果这个时候你已经更新了θ0 那么你会使用 θ0的新的值来计算这个微分项 所以由于你已经在这个公式中使用了新的 θ0的值 那么这会产生一个与左边不同的 temp1的值 所以右边并不是正确地实现梯度下降的做法</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561083_1129145205_1539945818" alt="_1526561083_1129145205_1539945818_1526561083_1129145205.png"></p>
<ul>
<li>我不打算解释为什么你需要同时更新 <strong>同时更新是梯度下降中的一种常用方法</strong> 我们之后会讲到 <strong>实际上同步更新是更自然的实现方法</strong> 当<strong>人们谈到梯度下降时 他们的意思就是同步更新</strong> 如果用非同步更新去实现算法 代码可能也会正确工作 但是右边的方法并不是人们所指的那个梯度下降算法 而是具有不同性质的其他算法 由于各种原因 这其中会表现出微小的差别 你应该做的是 在梯度下降中真正实现同时更新 这些就是梯度下降算法的梗概</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561100_393689345_1539945882" alt="_1526561100_393689345_1539945882_1526561100_393689345.png"></p>
<ul>
<li>在接下来的视频中 我们要进入这个微分项的细节之中 我已经写了出来但没有真正定义 如果你已经修过微积分课程 如果你熟悉偏导数和导数 这其实就是这个微分项 如果你不熟悉微积分 不用担心 即使你之前没有看过微积分 或者没有接触过偏导数 在接下来的视频中 你会得到一切你需要知道的 如何计算这个微分项的知识 下一个视频中 希望我们能够给出 实现梯度下降算法的所有知识</li>
</ul>
<h3 id="Gradient-Descennt笔记"><a href="#Gradient-Descennt笔记" class="headerlink" title="Gradient Descennt笔记"></a>Gradient Descennt笔记</h3><ul>
<li><p>所以我们有我们的<strong>假设函数</strong>，并且我们有一种测量它适合数据的方式。现在我们需要估计<strong>假设函数</strong>中的<strong>参数</strong>。这就是梯度下降的地方。</p>
</li>
<li><p>设想我们根据它的域<code>θ0</code>和<code>θ1</code>来描绘我们的假设函数（实际上我们将代价函数绘制为参数估计的函数）。我们不是图表x和y本身，而是我们的假设函数的参数范围和选择一组特定参数所产生的成本。</p>
</li>
<li><p>我们在x轴上放置θ0，在y轴上放置θ1，在垂直z轴上放置代价函数。我们图上的点将是使用我们的假设与那些特定theta参数的成本函数的结果。下面的图表描述了这样的设置。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561137_131391682_1539945928" alt="_1526561137_131391682_1539945928_1526561137_131391682.png"></p>
<ul>
<li><p><strong>当我们的代价函数处于图的坑底时，即当其值最小时，我们将知道我们已经成功了。红色箭头显示图表中的最小点</strong>。</p>
</li>
<li><p>我们这样做的方式是<strong>通过获取代价函数的导数（函数的切线）</strong>。<strong>切线的斜率是该点的导数</strong>，它会给我们一个走向的方向。我们逐步降低成本函数的下降速度。每一步的大小由<code>参数α</code>决定，称为<strong>学习率</strong>。</p>
</li>
<li><p>例如，<strong>上图中每个“星号”之间的距离代表由我们的参数α确定的一个步骤。 α越小，步长越小，α越大，步长越大。步进的方向取决于J（θ0，θ1）的偏导数</strong>。根据图表的起始位置，可能会出现不同的点。上面的图片向我们展示了两个不同的起点，最终在两个不同的地方。</p>
</li>
<li><p>梯度下降算法是：<br>重复，直到收敛：<br>  <img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561170_2045903942_1539945980" alt="_1526561170_2045903942_1539945980_1526561170_2045903942.png">j = 0,1代表特征索引号。</p>
</li>
<li><p>在每次迭代j中，应<strong>同时更新参数θ1，θ2，…，θn</strong>。在计算第j次迭代之前更新特定参数会导致错误的实现。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561190_832177929_1539945992" alt="_1526561190_832177929_1539945992_1526561190_832177929.png"></p>
<h2 id="Gradient-Descent-Intuition"><a href="#Gradient-Descent-Intuition" class="headerlink" title="Gradient Descent Intuition"></a>Gradient Descent Intuition</h2><blockquote>
<p>在之前的视频中 我们给出了一个数学上关于梯度 下降的定义 本次视频我们更深入研究一下 更直观地感受一下这个 算法是做什么的 以及梯度下降算法的更新过程有什么意义 这是我们上次视频中看到的梯度下降算法 提醒一下 这个<code>参数 α</code> 术语称为<code>学习速率</code> <strong>它控制我们以多大的幅度更新这个参数θj</strong>. 第二部分是导数项 而我在这个视频中要做的就是 给你一个更直观的认识 这两部分有什么用 以及 为什么当把 这两部分放一起时 整个更新过程是有意义的</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561218_1102222000_1539946039" alt="_1526561218_1102222000_1539946039_1526561218_1102222000.png"></p>
<ul>
<li>为了更好地让你明白 我要做是用一个稍微简单的例子 比如我们想最小化的那个 函数只有一个参数的情形 所以 <code>假如我们有一个代价函数J 只有一个参数 θ1</code> 就像我们前几次视频中讲的 θ1是一个实数 对吧？那么我们可以画出一维的曲线 看起来很简单 让我们试着去理解 为什么梯度下降法 会在这个函数上起作用</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561252_904671270_1539946074" alt="_1526561252_904671270_1539946074_1526561252_904671270.png"></p>
<ul>
<li>所以 假如这是我的函数 关于$\theta_1$的函数$J(\theta_1)$是一个实数 对吧？ 现在我们已经对这个点上用于梯度下降法的$\theta_1$ 进行了初始化 想象一下在我的函数图像上 从那个点出发 那么梯度下降 要做的事情是<strong>不断更新 θ1等于θ1减α倍的 <code>d/dθ1J(θ1)</code>这个项</strong> 对吧？哦 顺便插一句 你知道 这个微分项是吧？可能你想问为什么我改变了符号 之前用的是偏导数的符号 如果你不知道偏导数的符号 和<code>d/dθ</code>之间的区别是什么 不用担心 从技术上讲 在数学中 我们称这是一个<code>偏导数</code> 这是一个导数 这取决于函数J的参数数量 但是这是一个 数学上的区别 就本课的目标而言 可以默认为 这些偏导数符号 和<code>d/dθ1</code>是完全一样的东西 不用担心 是否存在任何差异 我会尽量使用数学上的 精确的符号 但就我们的目的而言 这些符号是没有区别的</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561410_371681908_1539946127" alt="_1526561410_371681908_1539946127_1526561410_371681908.png"></p>
<ul>
<li>好的 那么我们来看这个方程 我们要计算 这个导数 求导的目的 基本上可以说 <strong>取这一点的切线</strong> 就是这样一条红色的直线 刚好与函数相切于这一点 让我们看看这条红色直线的斜率 其实这就是导数 也就是说 直线的斜率 也就是这条 刚好与函数曲线相切的这条直线 这条直线的斜率正好是 这个<strong>高度除以这个水平长度</strong> 现在 这条线有 一个正斜率 也就是说它有正导数 因此 我得到的新的θ <strong>θ1更新后等于θ1减去一个正数乘以α</strong>. <strong>α 也就是学习速率也是一个正数</strong> 所以 我要使θ1减去一个东西 所以相当于我将θ1向左移 使θ1变小了</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561401_1069093686_1539946176" alt="_1526561401_1069093686_1539946176_1526561401_1069093686.png"></p>
<ul>
<li>我们可以看到 这么做是对的 因为实际上我<strong>往这个方向移动 确实让我更接近那边的最低点</strong> 所以 梯度下降到目前为止似乎 是在做正确的事</li>
<li>让我们来看看另一个例子 让我们用同样的函数J 同样再画出函数J(θ1)的图像 而这次 我们把参数初始化到左边这点 所以θ1在这里 同样把这点对应到曲线上 现在 导数项<code>d/dθ1J(θ1)</code>在这点上计算时 看上去会是这样 这条线的斜率 这个导数是这条线的斜率 但是这条线向下倾斜 所以这条线具有<strong>负斜率</strong> 对吧？ 或者说 这个函数有负导数 也就意味着在那一点上有负斜率 因此 这个导数项小于等于零 所以 当我<strong>更新θ时 θ被更新为θ减去α乘以一个负数 因此我是在用 θ1减去一个负数 这意味着我实际上是在增加θ1</strong> 对不对？因为这是减去一个负数 意味着给θ加上一个数 这就意味着最后我实际上增加了θ的值 因此 我们将 从这里开始 增加θ 似乎这也是我希望得到的 也就是 让我<strong>更接近最小值</strong>了</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561445_1568980368_1539946208" alt="_1526561445_1568980368_1539946208_1526561445_1568980368.png"></p>
<ul>
<li>所以 我希望这样很直观地给你解释了 导数项的意义 让我们接下来再看一看学习速率α 我们来研究一下它有什么用 这就是我梯度下降法的 更新规则 就是这个等式 让我们来看看如果α 太小或 α 太大  会出现什么情况 这第一个例子 α太小会发生什么呢 这是我的函数J(θ) 就从这里开始 <strong>如果α太小了 那么我要做的是要去 用一个比较小的数乘以更新的值</strong> 所以最终 它就像一个小宝宝的步伐 这是一步 然后从这个新的起点开始 迈出另一步 但是由于α 太小 因此只能迈出另一个 小碎步 所以如果我的学习速率太小 结果就是 只能这样像小宝宝一样一点点地挪动 去努力接近最低点 这样就需要很多步才能到达最低点 所以<strong>如果α 太小的话 可能会很慢 因为它会一点点挪动 它会需要 很多步才能到达全局最低点</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561464_253805835_1539946231" alt="_1526561464_253805835_1539946231_1526561464_253805835.png"></p>
<ul>
<li>那么如果α 太大又会怎样呢 这是我的函数J(θ) 如果α 太大 那么梯度下降法可能会越过最低点 甚至可能无法收敛 我的意思是 比如我们从这个点开始 实际上这个点已经接近最低点 因此导数指向右侧 但如果α 太大的话 我会迈出很大一步 也许像这样巨大的一步 对吧？所以我最终迈出了一大步 现在 我的代价函数变得更糟 因为离这个最低点越来越远 现在我的导数指向左侧 实际上在减小θ 但是你看 如果我的学习速率过大 我会移动一大步 从这点一下子又到那点了 对吗？如果我的学习率太大 下一次迭代 又移动了一大步 越过一次 又越过一次 一次次越过最低点 直到你发现 实际上 离最低点越来越远 所以 <strong>如果α太大 它会导致无法收敛 甚至发散</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561479_1021372496_1539946255" alt="_1526561479_1021372496_1539946255_1526561479_1021372496.png"></p>
<ul>
<li>现在 我还有一个问题 这问题挺狡猾的  如果我们<strong>预先把θ1 放在一个局部的最低点</strong> 你认为下一步梯度下降法会怎样工作？ 所以假设你将θ1初始化在局部最低点 假设这是你的θ1的初始值 在这儿 它已经在一个局部的 最优处或局部最低点 结果是<strong>局部最优点的导数 将等于零</strong> 因为它是那条切线的斜率 而这条线的斜率将等于零 因此 此导数项等于0 因此 在你的梯度下降更新过程中 你有一个θ1 然后用θ1 减α 乘以0来更新θ1 所以这意味着什么 这意味着你已经在局部最优点 它使得θ1不再改变 也就是<strong>新的θ1等于原来的θ1 因此 如果你的参数已经处于 局部最低点 那么梯度下降法更新其实什么都没做 它不会改变参数的值</strong> 这也正是你想要的 因为它使你的解始终保持在 局部最优点 这也解释了为什么即使学习速率α 保持不变时 梯度下降也可以收敛到局部最低点 我想说的是这个意思</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561493_322597671_1539946286" alt="_1526561493_322597671_1539946286_1526561493_322597671.png"></p>
<ul>
<li>我们来看一个例子 这是代价函数J(θ) 我想找到它的最小值 首先初始化我的梯度下降算法 在那个品红色的点初始化 如果我更新一步梯度下降 也许它会带我到这个点 因为这个点的导数是相当陡的 现在 在这个绿色的点 如果我再更新一步 你会发现我的导数 也即斜率 是没那么陡的 相比于在品红点 对吧？因为随着我接近最低点 我的导数越来越接近零 所以 <strong>梯度下降一步后 新的导数会变小一点点</strong> 然后我想再梯度下降一步 在这个绿点我自然会用一个稍微 跟刚才在那个品红点时比 再小一点的一步  现在到了新的点 红色点 更接近全局最低点了 因此这点的导数会比在绿点时更小 所以  我再进行一步梯度下降时 我的导数项是更小的 θ1更新的幅度就会更小 所以你会移动更小的一步 像这样 <strong>随着梯度下降法的运行  你移动的幅度会自动变得越来越小 直到最终移动幅度非常小 你会发现 已经收敛到局部极小值</strong> 所以回顾一下 <strong>在梯度下降法中 当我们接近局部最低点时 梯度下降法会自动采取 更小的幅度</strong> 这是因为当我们接近局部最低点时 很显然在<strong>局部最低时导数等于零</strong> 所以当我们 接近局部最低时 导数值会自动变得越来越小 所以梯度下降将自动采取较小的幅度 这就是梯度下降的做法 所以<strong>实际上没有必要再另外减小α 这就是梯度下降算法</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561559_975182746_1539946335" alt="_1526561559_975182746_1539946335_1526561559_975182746.png"></p>
<ul>
<li>你可以用它来最小化 最小化任何代价函数J 不只是线性回归中的代价函数J 在接下来的视频中 我们要用代价函数J 回到它的本质 线性回归中的代价函数 也就是我们前面得出的平方误差函数 结合梯度下降法 以及平方代价函数 我们会得出第一个机器学习算法 即线性回归算法</li>
</ul>
<h3 id="Gradient-Descent-Intuition笔记"><a href="#Gradient-Descent-Intuition笔记" class="headerlink" title="Gradient Descent Intuition笔记"></a>Gradient Descent Intuition笔记</h3><ul>
<li>在本视频中，我们探索了使用一个参数θ1并绘制其代价函数来实现梯度下降的场景。 我们的单一参数公式为：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561584_1088750870_1539946381" alt="_1526561584_1088750870_1539946381_1526561584_1088750870.png"></p>
<ul>
<li>无论<img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561607_175617464_1539946398" alt="_1526561607_175617464_1539946398_1526561607_175617464.png">的斜率符号如何，θ1最终收敛到其最小值。 下图显示<strong>当斜率为负值时，θ1的值增加，当为正值时，θ1的值减小</strong>。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561620_33298999_1539946410" alt="_1526561620_33298999_1539946410_1526561620_33298999.png"></p>
<ul>
<li>在附注中，我们应该调整<code>参数α</code>以确保梯度下降算法在合理的时间内收敛。 未能收敛或获得最小值的时间太多意味着我们的步长是错误的。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561636_1697292728_1539946422" alt="_1526561636_1697292728_1539946422_1526561636_1697292728.png"></p>
<ul>
<li>梯度下降如何以固定步长α收敛？<br>收敛背后的直觉是，当我们逼近我们的凸函数的底部时，<img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561656_442389494_1539946439" alt="_1526561656_442389494_1539946439_1526561656_442389494.png">接近0。 至少，派生将始终为0，因此我们得到：</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561667_1647461546_1539946468" alt="_1526561667_1647461546_1539946468_1526561667_1647461546.png"></p>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561675_2093920258_1539946481" alt="_1526561675_2093920258_1539946481_1526561675_2093920258.png"></p>
<h2 id="Gradient-Descent-For-Linear-Regression"><a href="#Gradient-Descent-For-Linear-Regression" class="headerlink" title="Gradient Descent For Linear Regression"></a>Gradient Descent For Linear Regression</h2><blockquote>
<p>在以前的视频中我们谈到 关于梯度下降算法 梯度下降是很常用的算法 它不仅被用在线性回归上 和线性回归模型、平方误差代价函数 在这段视频中 我们要 <strong>将<code>梯度下降</code> 和<code>代价函数</code>结合</strong> 在后面的视频中 我们将用到此算法 并将其应用于 具体的拟合直线的线性回归算法里 这就是 我们在之前的课程里所做的工作</p>
</blockquote>
<ul>
<li>这是<strong>梯度下降算法</strong> 这个算法你应该很熟悉 这是<strong>线性回归模型</strong> 还有<strong>线性假设</strong>和<strong>平方误差代价函数</strong> 我们将要做的就是 <strong>用梯度下降的方法 来最小化平方误差代价函数</strong> 为了 使梯度下降 为了 写这段代码 我们需要的<strong>关键项 是这里这个微分项</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561743_42538752_1539946555" alt="_1526561743_42538752_1539946555_1526561743_42538752.png"></p>
<ul>
<li>所以.我们需要弄清楚 这个偏导数项是什么 并结合这里的 代价函数J 的定义 就是这样 一个求和项 代价函数就是 这个误差平方项 我这样做 只是 <strong>把定义好的代价函数 插入了这个微分式 再简化一下</strong> 这等于是 这一个求和项 <code>θ0 + θ1x(i) - y(i)</code></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561818_666946699_1539946612" alt="_1526561818_666946699_1539946612_1526561818_666946699.png"></p>
<ul>
<li>实际上我们需要 弄清楚这两个 偏导数项是什么 这两项分别是 j=0 和j=1的情况 因此<strong>我们要弄清楚 θ0 和 θ1 对应的 偏导数项是什么</strong> (<strong>将上面的式子平方化开再分别对θ0 和θ1求偏导</strong>)</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561861_322362701_1539946651" alt="_1526561861_322362701_1539946651_1526561861_322362701.png"></p>
<ul>
<li>所以 偏导数项 从这个等式 到下面的等式 计算这些偏导数项需要一些多元微积分 如果你掌握了微积分 你可以随便自己推导这些 然后你检查你的微分 你实际上会得到我给出的答案 但如果你 不太熟悉微积分 别担心 你可以直接用这些 已经算出来的结果 你不需要掌握微积分 或者别的东西 来完成作业 你只需要会用梯度下降就可以</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561892_649652808_1539951959" alt="_1526561892_649652808_1539951959_1526561892_649652808.png"></p>
<ul>
<li>在定义这些以后 在我们算出 这些微分项以后 <strong>这些微分项 实际上就是代价函数J的斜率</strong> 现在可以将它们放回 我们的梯度下降算法 所以这就是<strong>专用于 线性回归的梯度下降 反复执行括号中的式子直到收敛</strong> <strong>θ0和θ1不断被更新 都是加上一个<code>-α/m</code> 乘上后面的求和项</strong> 所以这里这一项 所以这就是我们的<strong>线性回归算法</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561936_996217166_1539952078" alt="_1526561936_996217166_1539952078_1526561936_996217166.png"></p>
<ul>
<li>这一项就是<strong>关于θ0的偏导数</strong> 在上一张幻灯片中推出的</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561956_1952955701_1539952499" alt="_1526561956_1952955701_1539952499_1526561956_1952955701.png"></p>
<ul>
<li>而第二项 这一项是刚刚的推导出的 <strong>关于θ1的 偏导数项</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526561971_576823992_1539952519" alt="_1526561971_576823992_1539952519_1526561971_576823992.png"></p>
<ul>
<li>提醒一下 <strong>执行梯度下降时 有一个细节要注意 就是必须要 同时更新θ0和θ1</strong></li>
<li>所以 让我们来看看梯度下降是如何工作的 我们用梯度下降解决问题的 一个原因是 <strong>它更容易得到局部最优值</strong> 当我第一次解释梯度下降时 我展示过这幅图</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562028_517004246_1539952542" alt="_1526562028_517004246_1539952542_1526562028_517004246.png"></p>
<ul>
<li>在表面上 不断下降 并且我们知道了 根据你的初始化 你会得到不同的局部最优解 你知道.你可以结束了.在这里或这里。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562040_769496498_1539952555" alt="_1526562040_769496498_1539952555_1526562040_769496498.png"></p>
<ul>
<li>但是 <strong>事实证明 用于线性回归的 代价函数 总是这样一个 弓形的样子</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562056_1050624241_1539952593" alt="_1526562056_1050624241_1539952593_1526562056_1050624241.png"></p>
<ul>
<li>这个函数的专业术语是 这是一个<code>凸函数</code> 我不打算在这门课中 给出凸函数的定义 <code>凸函数(convex function)</code> 但不正式的说法是 它就是一个弓形的函数 因此 <strong>这个函数 没有任何局部最优解 只有一个全局最优解</strong> 并且<strong>无论什么时候 你对这种代价函数 使用线性回归 梯度下降法得到的结果 总是收敛到全局最优值</strong> 因为没有全局最优以外的其他局部最优点</li>
<li>现在 让我们来看看这个算法的执行过程 像往常一样 这是<code>假设函数</code>的图 还有<code>代价函数J</code>的图</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562070_1456917132_1539952610" alt="_1526562070_1456917132_1539952610_1526562070_1456917132.png"></p>
<ul>
<li>让我们来看看如何 初始化参数的值<strong>通常来说 初始化参数为零 θ0和θ1都在零</strong> 但为了展示需要 在这个梯度下降的实现中 我<strong>把θ0初始化为-900 θ1初始化为-0.1</strong></li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562104_573736577_1539952665" alt="_1526562104_573736577_1539952665_1526562104_573736577.png"></p>
<ul>
<li>现在进行一次梯度下降,从一点开始向左下方移动一小步,然后就得到了第二个点,假设函数的线改变了一点点.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562122_1863333386_1539952686" alt="_1526562122_1863333386_1539952686_1526562122_1863333386.png"></p>
<ul>
<li>不断的移动代价函数的点梯度不断下降,假设函数越来越拟合数据,,直到收敛到全局最小值</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562131_948800849_1539952693" alt="_1526562131_948800849_1539952693_1526562131_948800849.png"></p>
<ul>
<li>现在就可以用它来预测房价了.</li>
<li>“Batch”Gradient Descent:批量梯度下降:在梯度下降的每一步中,我们都用到了所有的训练样本</li>
<li>在梯度下降中,在计算微分求导项时,我们需要进行求和计算,所以在每一个单独的梯度计算中,我们最终都要计算这样一个东西—-这个项需要<strong>对所有m个训练样本求和</strong>.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/fengwenhua/ImageBed/master/_1526562146_1798195049_1539952711" alt="_1526562146_1798195049_1539952711_1526562146_1798195049.png"></p>

      
    </div>

    

    
    
    

    

    
      
    
    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="冯文华 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="冯文华 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/单变量线性回归/" rel="tag"><i class="fa fa-tag"></i> 单变量线性回归</a>
          
            <a href="/tags/Linear-Regression/" rel="tag"><i class="fa fa-tag"></i> Linear-Regression</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/15/第一章-Model-and-Cost-Function/" rel="next" title="第一章: Model and Cost Function">
                <i class="fa fa-chevron-left"></i> 第一章: Model and Cost Function
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/15/第三章-线性代数回顾-Linear-Algebra-Review/" rel="prev" title="第三章 线性代数回顾(Linear Algebra Review)">
                第三章 线性代数回顾(Linear Algebra Review) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">冯文华</p>
              <p class="site-description motion-element" itemprop="description">记录日常学习与生活</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                  
                    
                  
                  <a href="https://github.com/fengwenhua" title="GitHub &rarr; https://github.com/fengwenhua" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i></a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://lfasd.top" title="http://lfasd.top" rel="noopener" target="_blank">Lfasd</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-Descennt"><span class="nav-number">1.</span> <span class="nav-text">Gradient Descennt</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-Descennt笔记"><span class="nav-number">1.1.</span> <span class="nav-text">Gradient Descennt笔记</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-Descent-Intuition"><span class="nav-number">2.</span> <span class="nav-text">Gradient Descent Intuition</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-Descent-Intuition笔记"><span class="nav-number">2.1.</span> <span class="nav-text">Gradient Descent Intuition笔记</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-Descent-For-Linear-Regression"><span class="nav-number">3.</span> <span class="nav-text">Gradient Descent For Linear Regression</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">by fengwenhua</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">91k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">2:31</span>
  
</div>










        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  
    
      
  
  <script type="text/javascript" color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.5.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.5.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.5.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.5.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.5.0"></script>



  



  








  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: true,
        notify: true,
        appId: 'sDPAkIqXzfXIejgNvNYYQ1Ji-gzGzoHsz',
        appKey: '3yyuJ2OpBOhCms7yzBmA0Xbq',
        placeholder: 'Just go go',
        avatar:'mm',
        meta:guest,
        pageSize:'10' || 10,
        visitor: true
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      
        // ref: https://github.com/ForbesLindesay/unescape-html
        var unescapeHtml = function(html) {
          return String(html)
            .replace(/&quot;/g, '"')
            .replace(/&#39;/g, '\'')
            .replace(/&#x3A;/g, ':')
            // replace all the other &#x; chars
            .replace(/&#(\d+);/g, function (m, p) { return String.fromCharCode(p); })
            .replace(/&lt;/g, '<')
            .replace(/&gt;/g, '>')
            .replace(/&amp;/g, '&');
        };
      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                content = unescapeHtml(content);
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('复制成功')
          else $(this).text('复制失败')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>


  

</body>
</html>
<script type="text/javascript" src="/js/src/love.js"></script>
